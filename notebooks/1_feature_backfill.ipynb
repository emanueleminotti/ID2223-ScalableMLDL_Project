{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1f2881-7273-45ff-9259-537b23ad8ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /Users/woland02/VsCode/ID2223-ScalableMLDL_Project\n",
      "Added the following directory to the PYTHONPATH: /Users/woland02/VsCode/ID2223-ScalableMLDL_Project\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "if root_dir.parts[-1:] == ('notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir) \n",
    "print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f447120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b8d1a-62a5-4a1d-b805-6e83cafcd29f",
   "metadata": {},
   "source": [
    "## Hopsworks API Key\n",
    "You need to have registered an account on app.hopsworks.ai.\n",
    "\n",
    "Save the HOPSWORKS_API_KEY  to ~/.env file in the root directory of your project\n",
    "\n",
    "In the .env file, update HOPSWORKS_API_KEY:\n",
    "\n",
    "`HOPSWORKS_API_KEY=\"put API KEY value in this string\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-20 16:31:56,856 INFO: Initializing external client\n",
      "2025-12-20 16:31:56,858 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-20 16:31:58,664 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267872\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9145f0b7-d961-41f7-aebe-741dbf00784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hopsworks import RestAPIError\n",
    "\n",
    "api_url = \"https://air-quality-api.open-meteo.com/v1/air-quality\"\n",
    "country = \"Sweden\"\n",
    "city = \"Stockholm\"\n",
    "latitude = 59.3346 \n",
    "longitude = 18.0632"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Read the historical data into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical pollen levels data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3a1212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pollen data for Stockholm from 2013-01-01 to 2025-12-20...\n",
      "Data fetched successfully!\n",
      "                 time  alder_pollen  birch_pollen  grass_pollen  \\\n",
      "0 2013-01-01 00:00:00           NaN           NaN           NaN   \n",
      "1 2013-01-01 01:00:00           NaN           NaN           NaN   \n",
      "2 2013-01-01 02:00:00           NaN           NaN           NaN   \n",
      "3 2013-01-01 03:00:00           NaN           NaN           NaN   \n",
      "4 2013-01-01 04:00:00           NaN           NaN           NaN   \n",
      "\n",
      "   mugwort_pollen  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "Total rows: 113688\n"
     ]
    }
   ],
   "source": [
    "# Define the date range for historical data\n",
    "start_date = \"2013-01-01\"\n",
    "end_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define the pollen variables available in Open-Meteo\n",
    "# We don't consider olive and ragweed because they are negligible\n",
    "pollen_vars = [\n",
    "    \"alder_pollen\", \n",
    "    \"birch_pollen\", \n",
    "    \"grass_pollen\", \n",
    "    \"mugwort_pollen\"\n",
    "]\n",
    "\n",
    "# Set up the API parameters\n",
    "params = {\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"hourly\": \",\".join(pollen_vars), # Request all pollen types\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date,\n",
    "    \"timezone\": \"auto\" # Automatically match the city's timezone\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "print(f\"Fetching pollen data for {city} from {start_date} to {end_date}...\")\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    \n",
    "    # Convert the 'hourly' data into a Pandas DataFrame\n",
    "    hourly_data = response_json[\"hourly\"]\n",
    "    df_pollen = pd.DataFrame(hourly_data)\n",
    "    \n",
    "    # Convert the 'time' column to datetime objects and set it as the index\n",
    "    df_pollen[\"time\"] = pd.to_datetime(df_pollen[\"time\"])\n",
    "    \n",
    "    print(\"Data fetched successfully!\")\n",
    "    print(df_pollen.head())\n",
    "    print(f\"Total rows: {len(df_pollen)}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812eb37-04e3-4291-8d77-a69ef7a195bc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Data cleaning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and interpolation complete.\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "cols_to_keep = ['time', 'alder_pollen', 'birch_pollen', 'grass_pollen', 'mugwort_pollen']\n",
    "df_pollen_clean = df_pollen[cols_to_keep].copy()\n",
    "\n",
    "# Set index and Resample to Daily Mean\n",
    "df_pollen_clean.set_index('time', inplace=True)\n",
    "df_pollen_daily = df_pollen_clean.resample('D').mean()\n",
    "\n",
    "# Linear Interpolation for gaps\n",
    "# limit_direction='both' ensures we fill gaps based on surrounding data\n",
    "df_pollen_daily = df_pollen_daily.interpolate(method='time', limit_direction='both')\n",
    "\n",
    "df_pollen_daily.dropna(inplace=True)\n",
    "\n",
    "# Cast types\n",
    "pollen_cols = ['alder_pollen', 'birch_pollen', 'grass_pollen', 'mugwort_pollen']\n",
    "df_pollen_daily[pollen_cols] = df_pollen_daily[pollen_cols].astype('float32')\n",
    "\n",
    "# Reset index\n",
    "df_pollen_daily.reset_index(inplace=True)\n",
    "df_pollen_daily.rename(columns={'time': 'date'}, inplace=True)\n",
    "\n",
    "# Add country and city columns\n",
    "df_pollen_daily['country'] = country\n",
    "df_pollen_daily['city'] = city\n",
    "\n",
    "print(\"Data cleaning and interpolation complete.\")\n",
    "print(f\"Remaining missing values: {df_pollen_daily.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa32b9",
   "metadata": {},
   "source": [
    "### Adding lagged features\n",
    "\n",
    "To capture short-term temporal dependencies, we add three new features representing the pollen levels of the previous 1, 2, and 3 days.\n",
    "These lagged values will help the model learn patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba7dfa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with lagged features:\n",
      "        date  birch_pollen  birch_pollen_lag_1  birch_pollen_lag_2\n",
      "0 2013-01-04           0.0                 0.0                 0.0\n",
      "1 2013-01-05           0.0                 0.0                 0.0\n",
      "2 2013-01-06           0.0                 0.0                 0.0\n",
      "3 2013-01-07           0.0                 0.0                 0.0\n",
      "4 2013-01-08           0.0                 0.0                 0.0\n",
      "\n",
      "New DataFrame shape: (4734, 19)\n"
     ]
    }
   ],
   "source": [
    "# Define the pollen columns we want to lag\n",
    "pollen_cols = ['alder_pollen', 'birch_pollen', 'grass_pollen', 'mugwort_pollen']\n",
    "\n",
    "# Create the lagged features\n",
    "for col in pollen_cols:\n",
    "    for lag in range(1, 4):  # Loops through 1, 2, 3\n",
    "        # Name the new column, e.g., 'alder_pollen_lag_1'\n",
    "        lag_col_name = f\"{col}_lag_{lag}\"\n",
    "        # Shift the column data down by 'lag' rows\n",
    "        df_pollen_daily[lag_col_name] = df_pollen_daily[col].shift(lag)\n",
    "\n",
    "# Drop the first 3 rows which now contain NaNs (since we shifted up to 3 days)\n",
    "df_pollen_daily.dropna(inplace=True)\n",
    "\n",
    "# Reset index is generally good practice after dropping rows, though not strictly necessary if date is a column\n",
    "df_pollen_daily.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check the result\n",
    "print(\"Data with lagged features:\")\n",
    "print(df_pollen_daily[['date', 'birch_pollen', 'birch_pollen_lag_1', 'birch_pollen_lag_2']].head())\n",
    "print(f\"\\nNew DataFrame shape: {df_pollen_daily.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8276",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Download the Historical Weather Data </span>\n",
    "\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching historical weather data from 2013-01-04 to 2025-12-20...\n",
      "Weather data fetched successfully!\n",
      "        date  temperature_2m_max  temperature_2m_min  temperature_2m_mean  \\\n",
      "0 2013-01-04                 2.7                -0.3                  1.6   \n",
      "1 2013-01-05                -0.4                -3.6                 -2.2   \n",
      "2 2013-01-06                -0.2                -3.8                 -1.7   \n",
      "3 2013-01-07                 0.8                -4.8                 -1.2   \n",
      "4 2013-01-08                 1.3                -2.5                  0.0   \n",
      "\n",
      "   precipitation_sum  rain_sum  snowfall_sum  wind_speed_10m_max  \\\n",
      "0                0.0       0.0          0.00           23.200001   \n",
      "1                0.0       0.0          0.00           16.900000   \n",
      "2                0.0       0.0          0.00            9.400000   \n",
      "3                0.0       0.0          0.00           15.100000   \n",
      "4                2.5       0.1          1.75           18.400000   \n",
      "\n",
      "   wind_direction_10m_dominant  weather_code country       city  \n",
      "0                        309.0           3.0  Sweden  Stockholm  \n",
      "1                        322.0           3.0  Sweden  Stockholm  \n",
      "2                         30.0           3.0  Sweden  Stockholm  \n",
      "3                        219.0           3.0  Sweden  Stockholm  \n",
      "4                        247.0          73.0  Sweden  Stockholm  \n",
      "Shape: (4734, 12)\n"
     ]
    }
   ],
   "source": [
    "# Get the earliest date from the pollen DataFrame\n",
    "start_date = df_pollen_daily['date'].min().strftime('%Y-%m-%d')\n",
    "end_date = datetime.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Fetching historical weather data from {start_date} to {end_date}...\")\n",
    "\n",
    "# Define the Weather API URL (Archive API for history)\n",
    "weather_api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Define relevant weather variables for pollen prediction\n",
    "weather_vars = [\n",
    "    \"temperature_2m_max\",\n",
    "    \"temperature_2m_min\", \n",
    "    \"temperature_2m_mean\",\n",
    "    \"precipitation_sum\",\n",
    "    \"rain_sum\",\n",
    "    \"snowfall_sum\",\n",
    "    \"wind_speed_10m_max\",\n",
    "    \"wind_direction_10m_dominant\",\n",
    "    \"weather_code\"\n",
    "]\n",
    "\n",
    "# Set up the API parameters\n",
    "params = {\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date,\n",
    "    \"daily\": \",\".join(weather_vars),\n",
    "    \"timezone\": \"auto\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(weather_api_url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    daily_data = response_json[\"daily\"]\n",
    "    df_weather = pd.DataFrame(daily_data)\n",
    "    \n",
    "    # Data Cleaning for Weather Data\n",
    "    # Convert 'time' to datetime\n",
    "    df_weather[\"time\"] = pd.to_datetime(df_weather[\"time\"])\n",
    "    df_weather.rename(columns={\"time\": \"date\"}, inplace=True)\n",
    "    \n",
    "    # Cast float columns to float32 to save memory\n",
    "    float_cols = [c for c in df_weather.columns if c != \"date\"]\n",
    "    df_weather[float_cols] = df_weather[float_cols].astype(\"float32\")\n",
    "\n",
    "    df_weather[\"country\"] = country\n",
    "    df_weather[\"city\"] = city\n",
    "    \n",
    "    print(\"Weather data fetched successfully!\")\n",
    "    print(df_weather.head())\n",
    "    print(f\"Shape: {df_weather.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to fetch weather data. Status: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4734 entries, 0 to 4733\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         4734 non-null   datetime64[ns]\n",
      " 1   temperature_2m_max           4734 non-null   float32       \n",
      " 2   temperature_2m_min           4734 non-null   float32       \n",
      " 3   temperature_2m_mean          4734 non-null   float32       \n",
      " 4   precipitation_sum            4734 non-null   float32       \n",
      " 5   rain_sum                     4734 non-null   float32       \n",
      " 6   snowfall_sum                 4734 non-null   float32       \n",
      " 7   wind_speed_10m_max           4734 non-null   float32       \n",
      " 8   wind_direction_10m_dominant  4734 non-null   float32       \n",
      " 9   weather_code                 4734 non-null   float32       \n",
      " 10  country                      4734 non-null   object        \n",
      " 11  city                         4734 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(9), object(2)\n",
      "memory usage: 277.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f77aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-20 16:39:56,001 INFO: \t4 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267872/fs/1254483/fg/1867187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4734/4734 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: pollen_measurements_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267872/jobs/named/pollen_measurements_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('pollen_measurements_1_offline_fg_materialization', 'PYSPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"mugwort_pollen\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 10000.0\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 794654\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 4734,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-12-20T03:39:56.000000Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"alder_pollen\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 10000.0\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 794653\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 4734,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-12-20T03:39:56.000000Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"birch_pollen\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 10000.0\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 794652\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 4734,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-12-20T03:39:56.000000Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"grass_pollen\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 10000.0\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 794651\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"element_count\": 4734,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-12-20T03:39:56.000000Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 4,\n",
       "     \"successful_expectations\": 4,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"pollen_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-12-20T16:39:56.000883+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"22716888-ddba-11f0-8520-5ece7dce4837\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251220T153956.000769Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure correct dtype and PK column required by the existing FG\n",
    "df_pollen_daily[\"date\"] = pd.to_datetime(df_pollen_daily[\"date\"])\n",
    "df_pollen_daily[\"date_str\"] = df_pollen_daily[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optional: drop unused columns (BUT KEEP date_str!)\n",
    "df_pollen_daily = df_pollen_daily.drop(columns=[\"country\", \"city\"], errors=\"ignore\")\n",
    "\n",
    "# IMPORTANT: use the existing FG schema (version=1 expects date_str as PK)\n",
    "pollen_fg = fs.get_or_create_feature_group(\n",
    "    name=\"pollen_measurements\",\n",
    "    description=\"Daily average pollen levels for Stockholm\",\n",
    "    version=1,\n",
    "    primary_key=[\"date_str\"],   # must match the existing FG\n",
    "    event_time=\"date\"\n",
    ")\n",
    "\n",
    "# Insert\n",
    "pollen_fg.insert(df_pollen_daily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2afcaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_fg.update_feature_description(\n",
    "    \"date\", \"Date of the pollen measurement (Timestamp)\"\n",
    ")\n",
    "pollen_fg.update_feature_description(\n",
    "    \"date_str\", \"Date of the pollen measurement (YYYY-MM-DD, primary key)\"\n",
    ")\n",
    "pollen_fg.update_feature_description(\n",
    "    \"alder_pollen\", \"Daily average Alder pollen concentration (grains/m¬≥)\"\n",
    ")\n",
    "pollen_fg.update_feature_description(\n",
    "    \"birch_pollen\", \"Daily average Birch pollen concentration (grains/m¬≥)\"\n",
    ")\n",
    "pollen_fg.update_feature_description(\n",
    "    \"grass_pollen\", \"Daily average Grass pollen concentration (grains/m¬≥)\"\n",
    ")\n",
    "pollen_fg.update_feature_description(\n",
    "    \"mugwort_pollen\", \"Daily average Mugwort pollen concentration (grains/m¬≥)\"\n",
    ")\n",
    "\n",
    "# Lagged features\n",
    "for pollen_type in [\"alder_pollen\", \"birch_pollen\", \"grass_pollen\", \"mugwort_pollen\"]:\n",
    "    for i in range(1, 4):\n",
    "        col_name = f\"{pollen_type}_lag_{i}\"\n",
    "        if col_name in df_pollen_daily.columns:\n",
    "            pollen_fg.update_feature_description(\n",
    "                col_name,\n",
    "                f\"{pollen_type} concentration {i} day(s) prior\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation Suite already exists -> deleting & re-attaching...\n",
      "Attached expectation suite to Feature Group, edit it at https://c.app.hopsworks.ai:443/p/1267872/fs/1254483/fg/1840724\n",
      "Expectation Suite re-attached.\n",
      "2025-12-20 16:50:41,033 INFO: \t8 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1267872/fs/1254483/fg/1840724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4734/4734 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x163091990>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare / clean data (stable)\n",
    "# -----------------------------\n",
    "df_weather[\"date\"] = pd.to_datetime(df_weather[\"date\"])\n",
    "\n",
    "# Add a daily identifier (useful PK for daily data)\n",
    "df_weather[\"date_str\"] = df_weather[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Ensure PK uniqueness (recommended for idempotent inserts)\n",
    "df_weather = (\n",
    "    df_weather\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Get the Feature Store handle\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# -----------------------------\n",
    "# Feature Group (stable schema)\n",
    "# -----------------------------\n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=\"weather_measurements\",\n",
    "    version=1,\n",
    "    primary_key=[\"country\", \"city\", \"date_str\"],  # <-- daily PK\n",
    "    event_time=\"date\",                            # <-- event time for point-in-time\n",
    "    description=\"Daily weather data for Stockholm\",\n",
    "    online_enabled=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Expectation Suite (idempotent)\n",
    "# -----------------------------\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "# --- Temperature (Stockholm extremes) ---\n",
    "for temp_col in [\"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\"]:\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_be_between\",\n",
    "            kwargs={\"column\": temp_col, \"min_value\": -50.0, \"max_value\": 50.0}\n",
    "        )\n",
    "    )\n",
    "\n",
    "# --- Non-negative physical quantities ---\n",
    "non_negative_cols = [\"precipitation_sum\", \"rain_sum\", \"snowfall_sum\", \"wind_speed_10m_max\"]\n",
    "for col in non_negative_cols:\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_be_between\",\n",
    "            kwargs={\"column\": col, \"min_value\": 0.0, \"max_value\": 1000.0}\n",
    "        )\n",
    "    )\n",
    "\n",
    "# --- Wind Direction (0-360 degrees) ---\n",
    "weather_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"wind_direction_10m_dominant\", \"min_value\": 0.0, \"max_value\": 360.0}\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save / Update Expectations (idempotent for HSFS)\n",
    "try:\n",
    "    weather_fg.save_expectation_suite(expectation_suite=weather_expectation_suite)\n",
    "    print(\"Expectation Suite created and attached.\")\n",
    "except Exception as e:\n",
    "    msg = str(e)\n",
    "    if (\"already attached\" in msg) or (\"409\" in msg) or (\"Conflict\" in msg):\n",
    "        print(\"Expectation Suite already exists -> deleting & re-attaching...\")\n",
    "        # HSFS doesn't have update_expectation_suite in your version\n",
    "        weather_fg.delete_expectation_suite()\n",
    "        weather_fg.save_expectation_suite(expectation_suite=weather_expectation_suite)\n",
    "        print(\"Expectation Suite re-attached.\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# --- Align dataframe to existing FG schema (v1 has NO country/city) ---\n",
    "df_weather = df_weather.drop(columns=[\"country\", \"city\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Insert data (rerunnable)\n",
    "# -----------------------------\n",
    "# IMPORTANT: avoid overwrite=True here (can trigger backend clear/metadata ops)\n",
    "weather_fg.insert(df_weather)\n",
    "\n",
    "# -----------------------------\n",
    "# Feature descriptions\n",
    "# -----------------------------\n",
    "weather_fg.update_feature_description(\"date\", \"Date of the weather measurement (Timestamp)\")\n",
    "weather_fg.update_feature_description(\"date_str\", \"Date string (YYYY-MM-DD) used as daily primary key\")\n",
    "\n",
    "weather_fg.update_feature_description(\"temperature_2m_max\", \"Maximum daily air temperature at 2 meters (¬∞C)\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_min\", \"Minimum daily air temperature at 2 meters (¬∞C)\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Mean daily air temperature at 2 meters (¬∞C)\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Sum of daily precipitation (rain + showers + snow) (mm)\")\n",
    "weather_fg.update_feature_description(\"rain_sum\", \"Sum of daily rain (mm)\")\n",
    "weather_fg.update_feature_description(\"snowfall_sum\", \"Sum of daily snowfall (cm)\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Maximum wind speed at 10 meters (km/h)\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant wind direction at 10 meters (¬∞)\")\n",
    "weather_fg.update_feature_description(\"weather_code\", \"WMO Weather code (0-99) indicating general conditions\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
