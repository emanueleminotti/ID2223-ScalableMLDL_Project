{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Œ Login Hopsworks...\n",
      "2025-12-20 18:40:51,829 INFO: Closing external client and cleaning up certificates.\n",
      "2025-12-20 18:40:51,832 INFO: Connection closed.\n",
      "2025-12-20 18:40:51,834 INFO: Initializing external client\n",
      "2025-12-20 18:40:51,834 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-20 18:40:52,595 WARNING: UserWarning: The installed hopsworks client version 4.6.0 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-20 18:40:53,495 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267872\n",
      "ðŸ“Œ Feature View: pollen_stockholm_fv v1\n",
      "ðŸ“¦ Recupero modello: pollen_stockholm_xgboost (versione: latest)\n",
      "2025-12-20 18:40:56,906 WARNING: VersionWarning: No version provided for getting model `pollen_stockholm_xgboost`, defaulting to `1`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1e5710bb7e4959a3e8210d320e17a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/10825223 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modello scaricato in: /var/folders/57/stqc67wn4wd3zdl6qg664yh40000gn/T/7c587be1-c869-4cd9-b6cd-a108d56bbc71/pollen_stockholm_xgboost/1\n",
      "ðŸ“¦ Contenuto model_dir:\n",
      "\n",
      "DIR: .\n",
      "  - pollen_xgboost_model.pkl\n",
      "âœ… Modello caricato da (preferred): /var/folders/57/stqc67wn4wd3zdl6qg664yh40000gn/T/7c587be1-c869-4cd9-b6cd-a108d56bbc71/pollen_stockholm_xgboost/1/pollen_xgboost_model.pkl\n",
      "âœ… Modello caricato.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "\n",
    "# =========================\n",
    "# CONFIG (CAMBIA QUI)\n",
    "# =========================\n",
    "FV_NAME = os.getenv(\"FV_NAME\", \"pollen_stockholm_fv\")   # <-- nome Feature View\n",
    "FV_VERSION = int(os.getenv(\"FV_VERSION\", \"1\"))\n",
    "\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"pollen_stockholm_xgboost\")  # <-- nome nel Model Registry\n",
    "MODEL_VERSION = os.getenv(\"MODEL_VERSION\")  # None => prendi latest\n",
    "\n",
    "CITY = os.getenv(\"CITY\", \"stockholm\")\n",
    "\n",
    "FORECAST_HORIZON_DAYS = int(os.getenv(\"FORECAST_HORIZON_DAYS\", \"7\"))\n",
    "\n",
    "# Dove salvare output per UI dentro Hopsworks (Dataset)\n",
    "DATASET_BASE_DIR = os.getenv(\"DATASET_BASE_DIR\", \"Resources/pollen_forecasts\")\n",
    "\n",
    "# Se vuoi anche un FG di monitoring (opzionale)\n",
    "WRITE_MONITORING_FG = os.getenv(\"WRITE_MONITORING_FG\", \"true\").lower() == \"true\"\n",
    "MONITORING_FG_NAME = os.getenv(\"MONITORING_FG_NAME\", \"pollen_predictions\")\n",
    "MONITORING_FG_VERSION = int(os.getenv(\"MONITORING_FG_VERSION\", \"1\"))\n",
    "\n",
    "# Colonne che NON devono entrare nel modello (come nel training)\n",
    "FEATURES_TO_DROP = [\"city\", \"country\", \"date\", \"date_str\", \"time\", \"unix_time\"]\n",
    "\n",
    "# =========================\n",
    "# UTILS\n",
    "# =========================\n",
    "def _safe_to_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Converte tutto a numerico per XGBoost, coerente col fix del training.\"\"\"\n",
    "    out = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "    return out\n",
    "\n",
    "def _infer_target_columns(pred_array: np.ndarray, fv) -> list[str]:\n",
    "    \"\"\"\n",
    "    Prova a ricostruire i nomi target in modo robusto.\n",
    "    - Se sai giÃ  i target: mettili hard-coded.\n",
    "    - Altrimenti prova da feature view/metadata.\n",
    "    \"\"\"\n",
    "    # Se vuoi hardcodare:\n",
    "    # return [\"alder_pollen\", \"birch_pollen\", \"grass_pollen\", ...]\n",
    "    # Fallback generico:\n",
    "    return [f\"target_{i}\" for i in range(pred_array.shape[1])]\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "print(\"ðŸ”Œ Login Hopsworks...\")\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "print(f\"ðŸ“Œ Feature View: {FV_NAME} v{FV_VERSION}\")\n",
    "feature_view = fs.get_feature_view(name=FV_NAME, version=FV_VERSION)\n",
    "print(f\"ðŸ“¦ Recupero modello: {MODEL_NAME} (versione: {MODEL_VERSION or 'latest'})\")\n",
    "if MODEL_VERSION:\n",
    "    hs_model = mr.get_model(MODEL_NAME, version=int(MODEL_VERSION))\n",
    "else:\n",
    "    hs_model = mr.get_model(MODEL_NAME)\n",
    "\n",
    "model_dir = hs_model.download()\n",
    "print(f\"âœ… Modello scaricato in: {model_dir}\")\n",
    "\n",
    "# --- Debug: stampa contenuto cartelle (opzionale ma utile) ---\n",
    "print(\"ðŸ“¦ Contenuto model_dir:\")\n",
    "for root, dirs, files in os.walk(model_dir):\n",
    "    rel = os.path.relpath(root, model_dir)\n",
    "    print(f\"\\nDIR: {rel}\")\n",
    "    for f in files:\n",
    "        print(\"  -\", f)\n",
    "\n",
    "# =========================================================\n",
    "# Loader robusto (coerente col tuo training)\n",
    "# 1) prova prima pollen_xgboost_model.pkl\n",
    "# 2) fallback: cerca qualsiasi .pkl/.joblib/.pickle\n",
    "# =========================================================\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "def find_file_recursive(base_dir: str, filename: str) -> str | None:\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "    return None\n",
    "\n",
    "loaded_model = None\n",
    "\n",
    "# 1) Nome atteso dal tuo notebook 3\n",
    "preferred = find_file_recursive(model_dir, \"pollen_xgboost_model.pkl\")\n",
    "if preferred is not None:\n",
    "    loaded_model = joblib.load(preferred)\n",
    "    print(f\"âœ… Modello caricato da (preferred): {preferred}\")\n",
    "else:\n",
    "    # 2) fallback: qualsiasi file modello\n",
    "    candidates = []\n",
    "    for root, _, files in os.walk(model_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".joblib\", \".pkl\", \".pickle\")):\n",
    "                candidates.append(os.path.join(root, f))\n",
    "\n",
    "    print(\"ðŸ”Ž Candidati trovati:\", candidates)\n",
    "\n",
    "    # prova joblib prima\n",
    "    for path in candidates:\n",
    "        try:\n",
    "            loaded_model = joblib.load(path)\n",
    "            print(f\"âœ… Modello caricato con joblib da: {path}\")\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # poi pickle\n",
    "    if loaded_model is None:\n",
    "        for path in candidates:\n",
    "            try:\n",
    "                with open(path, \"rb\") as f:\n",
    "                    loaded_model = pickle.load(f)\n",
    "                print(f\"âœ… Modello caricato con pickle da: {path}\")\n",
    "                break\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "if loaded_model is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Non ho trovato/letto un artifact modello dentro: {model_dir}\\n\"\n",
    "        \"Attesi: pollen_xgboost_model.pkl (dal training) oppure un qualsiasi .pkl/.joblib/.pickle.\"\n",
    "    )\n",
    "\n",
    "print(\"âœ… Modello caricato.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Forecast window: 2025-12-21 -> 2025-12-27 (7 giorni)\n",
      "ðŸ“¦ Carico train/test split version=1 (materializzato) ...\n",
      "âš ï¸ Nessuna riga esatta nel range futuro. Fallback: uso gli ultimi 7 giorni disponibili in X_test.\n",
      "âœ… Batch data pronti: 7 righe, 25 colonne\n",
      "                          date\n",
      "1562 2025-12-05 00:00:00+00:00\n",
      "1563 2025-12-06 00:00:00+00:00\n",
      "1564 2025-12-09 00:00:00+00:00\n",
      "1565 2025-12-13 00:00:00+00:00\n",
      "1566 2025-12-15 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "today = dt.date.today()\n",
    "start_date = today + dt.timedelta(days=1)\n",
    "end_date = start_date + dt.timedelta(days=FORECAST_HORIZON_DAYS - 1)\n",
    "\n",
    "print(f\"ðŸ“… Forecast window: {start_date} -> {end_date} ({FORECAST_HORIZON_DAYS} giorni)\")\n",
    "\n",
    "# =========================================================\n",
    "# FIX DEFINITIVO: usa i dati materializzati del training dataset\n",
    "# (evita Feature Query Service che non supporta delta connector)\n",
    "# =========================================================\n",
    "\n",
    "# Se vuoi forzare una versione specifica del training dataset, setta TRAIN_DATASET_VERSION\n",
    "TRAIN_DATASET_VERSION = int(os.getenv(\"TRAIN_DATASET_VERSION\", \"1\"))\n",
    "\n",
    "print(f\"ðŸ“¦ Carico train/test split version={TRAIN_DATASET_VERSION} (materializzato) ...\")\n",
    "X_train, X_test, y_train_tmp, y_test_tmp = feature_view.get_train_test_split(TRAIN_DATASET_VERSION)\n",
    "\n",
    "# Usiamo X_test come \"proxy\" del futuro: prendiamo le righe piÃ¹ recenti\n",
    "if \"date\" not in X_test.columns:\n",
    "    raise ValueError(f\"âŒ X_test non contiene 'date'. Colonne: {list(X_test.columns)}\")\n",
    "\n",
    "X_test = X_test.copy()\n",
    "X_test[\"date\"] = pd.to_datetime(X_test[\"date\"])\n",
    "\n",
    "# Ordina per data e prendi gli ultimi HORIZON_DAYS\n",
    "X_test = X_test.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Se vuoi proprio la finestra start/end, prova a filtrare; se vuoto, fallback agli ultimi 7\n",
    "mask = (X_test[\"date\"].dt.date >= start_date) & (X_test[\"date\"].dt.date <= end_date)\n",
    "batch_df = X_test.loc[mask].copy()\n",
    "\n",
    "if batch_df.empty:\n",
    "    print(\"âš ï¸ Nessuna riga esatta nel range futuro. Fallback: uso gli ultimi 7 giorni disponibili in X_test.\")\n",
    "    batch_df = X_test.tail(FORECAST_HORIZON_DAYS).copy()\n",
    "\n",
    "# Se city non c'Ã¨, aggiungila\n",
    "if \"city\" not in batch_df.columns:\n",
    "    batch_df[\"city\"] = CITY\n",
    "\n",
    "print(f\"âœ… Batch data pronti: {len(batch_df)} righe, {batch_df.shape[1]} colonne\")\n",
    "print(batch_df[[\"date\"]].head())\n",
    "\n",
    "# =========================================================\n",
    "# 2) Selezione feature e FIX dtype (come training)\n",
    "# =========================================================\n",
    "train_cols = [c for c in batch_df.columns if c not in FEATURES_TO_DROP]\n",
    "X_batch_raw = batch_df[train_cols].copy()\n",
    "\n",
    "X_batch = _safe_to_numeric(X_batch_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Predict...\n",
      "âœ… Predizioni generate.\n",
      "                       date    date_str       city  alder_pollen  \\\n",
      "0 2025-12-05 00:00:00+00:00  2025-12-05  stockholm      0.001625   \n",
      "1 2025-12-06 00:00:00+00:00  2025-12-06  stockholm     -0.000348   \n",
      "2 2025-12-09 00:00:00+00:00  2025-12-09  stockholm      0.000079   \n",
      "\n",
      "   birch_pollen  grass_pollen  mugwort_pollen  \n",
      "0      0.000201      0.000016        0.000008  \n",
      "1      0.000121     -0.000049       -0.000025  \n",
      "2      0.000174      0.000074       -0.000005  \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Predizione\n",
    "# =========================\n",
    "print(\"ðŸ¤– Predict...\")\n",
    "\n",
    "POLLENS = [\"alder_pollen\", \"birch_pollen\", \"grass_pollen\", \"mugwort_pollen\"]\n",
    "\n",
    "y_pred = loaded_model.predict(X_batch)\n",
    "\n",
    "# Normalizza shape\n",
    "y_pred = np.asarray(y_pred)\n",
    "if y_pred.ndim == 1:\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "# Controllo dimensioni: devono essere 4 output\n",
    "if y_pred.shape[1] != len(POLLENS):\n",
    "    raise ValueError(\n",
    "        f\"âŒ Il modello ha prodotto {y_pred.shape[1]} output, ma la UI si aspetta {len(POLLENS)}: {POLLENS}.\\n\"\n",
    "        \"Probabile mismatch tra ordine/numero target del training e quello atteso dalla UI.\"\n",
    "    )\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, columns=POLLENS)\n",
    "\n",
    "# Costruisci out_df con date/date_str/city + predizioni\n",
    "out_df = batch_df.copy()\n",
    "\n",
    "# Assicura colonne tempo\n",
    "out_df[\"date\"] = pd.to_datetime(out_df[\"date\"])\n",
    "if \"date_str\" not in out_df.columns:\n",
    "    out_df[\"date_str\"] = out_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Assicura city\n",
    "if \"city\" not in out_df.columns:\n",
    "    out_df[\"city\"] = CITY\n",
    "\n",
    "# Tieni solo le colonne utili + pred\n",
    "out_df = pd.concat(\n",
    "    [out_df[[\"date\", \"date_str\", \"city\"]].reset_index(drop=True),\n",
    "     pred_df.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "out_df = out_df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "print(\"âœ… Predizioni generate.\")\n",
    "print(out_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scritto file UI: latest_forecasts.json\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Salvataggio output per UI (latest_forecasts.json)\n",
    "# =========================\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "POLLENS = [\"alder_pollen\", \"birch_pollen\", \"grass_pollen\", \"mugwort_pollen\"]\n",
    "FORECAST_PATH = \"latest_forecasts.json\"   # <-- deve matchare app.py\n",
    "\n",
    "# out_df deve avere: date (datetime), e le 4 colonne POLLENS\n",
    "ui_df = out_df.sort_values(\"date\").head(FORECAST_HORIZON_DAYS).copy()\n",
    "ui_df[\"date\"] = pd.to_datetime(ui_df[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "payload = {\n",
    "    \"generated_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "    \"forecasts\": {}\n",
    "}\n",
    "\n",
    "for p in POLLENS:\n",
    "    if p not in ui_df.columns:\n",
    "        raise ValueError(f\"âŒ Manca colonna '{p}' in out_df. Colonne: {list(ui_df.columns)}\")\n",
    "\n",
    "    payload[\"forecasts\"][p] = [\n",
    "        {\"date\": d, \"value\": float(v)}\n",
    "        for d, v in zip(ui_df[\"date\"].tolist(), ui_df[p].tolist())\n",
    "    ]\n",
    "\n",
    "with open(FORECAST_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Scritto file UI: {FORECAST_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) (Opzionale) Monitoring Feature Group\n",
    "# =========================\n",
    "\n",
    "\n",
    "if WRITE_MONITORING_FG:\n",
    "    print(f\"ðŸ“ˆ Writing monitoring FG: {MONITORING_FG_NAME} v{MONITORING_FG_VERSION}\")\n",
    "\n",
    "    POLLENS = [\"alder_pollen\", \"birch_pollen\", \"grass_pollen\", \"mugwort_pollen\"]\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1) Prepara dataframe pulito per monitoring\n",
    "    # -------------------------------------------------\n",
    "    mon_df = out_df.copy()\n",
    "    mon_df[\"date\"] = pd.to_datetime(mon_df[\"date\"])\n",
    "\n",
    "    if \"date_str\" not in mon_df.columns:\n",
    "        mon_df[\"date_str\"] = mon_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if \"city\" not in mon_df.columns:\n",
    "        mon_df[\"city\"] = CITY\n",
    "\n",
    "    keep_cols = [\"city\", \"date\", \"date_str\"] + POLLENS\n",
    "    missing = [c for c in keep_cols if c not in mon_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"âŒ Colonne mancanti per monitoring FG: {missing}\")\n",
    "\n",
    "    mon_df = mon_df[keep_cols].copy()\n",
    "\n",
    "    # Forza pollini a float\n",
    "    for p in POLLENS:\n",
    "        mon_df[p] = (\n",
    "            pd.to_numeric(mon_df[p], errors=\"coerce\")\n",
    "            .fillna(0.0)\n",
    "            .astype(\"float32\")\n",
    "        )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2) Deduplica su chiave primaria (city, date_str)\n",
    "    # -------------------------------------------------\n",
    "    mon_df = (\n",
    "        mon_df\n",
    "        .sort_values(\"date\")                      # ordine deterministico\n",
    "        .drop_duplicates(\n",
    "            subset=[\"city\", \"date_str\"],\n",
    "            keep=\"last\"                           # tieni previsione piÃ¹ recente\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(f\"ðŸ”Ž Monitoring DF dopo deduplica: {len(mon_df)} righe\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) Crea o recupera Feature Group\n",
    "    # -------------------------------------------------\n",
    "    mon_fg = fs.get_or_create_feature_group(\n",
    "        name=MONITORING_FG_NAME,\n",
    "        version=MONITORING_FG_VERSION,\n",
    "        description=\"Pollen predictions for monitoring and hindcast\",\n",
    "        primary_key=[\"city\", \"date_str\"],\n",
    "        event_time=\"date\"\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 4) Inserimento (insert semplice, robusto)\n",
    "    # -------------------------------------------------\n",
    "    mon_fg.insert(mon_df, wait=True)\n",
    "    print(\"âœ… Monitoring FG aggiornato.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
